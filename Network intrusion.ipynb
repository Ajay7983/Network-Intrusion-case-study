{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea4753f7-906d-499f-8d4b-ed0afe0be997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "036bb9ed-3687-41a5-bb63-9eb096026fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "files = [\n",
    "    'Data_of_Attack_Back_Normal.csv',\n",
    "    'Data_of_Attack_Back.csv',\n",
    "    'Data_of_Attack_Back_BufferOverflow.csv',\n",
    "    'Data_of_Attack_Back_FTPWrite.csv',\n",
    "    'Data_of_Attack_Back_GuessPassword.csv',\n",
    "    'Data_of_Attack_Back_Neptune.csv',\n",
    "    'Data_of_Attack_Back_NMap.csv',\n",
    "    'Data_of_Attack_Back_PortSweep.csv',\n",
    "    'Data_of_Attack_Back_RootKit.csv',\n",
    "    'Data_of_Attack_Back_Satan.csv',\n",
    "    'Data_of_Attack_Back_Smurf.csv'\n",
    "]\n",
    "\n",
    "# Load all files into a list of dataframes\n",
    "dataframes = [pd.read_csv('C:/Users/Ajay/Downloads/Machine learning capstone project/Capstone Project 2/' + file) for file in files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23009d-dda0-47b3-bb46-f5538ddc2d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c00ac5c7-f427-4fe9-9258-a602491d61fd",
   "metadata": {},
   "source": [
    "# Add Attack Column: Add a new column attack to each dataframe to denote the type of attack or normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75a753a5-64cd-4235-a51c-c34016c9d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_labels = [\n",
    "    'Normal', 'Back', 'BufferOverflow', 'FTPWrite', 'GuessPassword',\n",
    "    'Neptune', 'NMap', 'PortSweep', 'RootKit', 'Satan', 'Smurf'\n",
    "]\n",
    "\n",
    "for df, label in zip(dataframes, attack_labels):\n",
    "    df['attack'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6307f7c-6185-4e0d-a3c5-f112e90d572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes[3].columns = ['duration', ' protocol_type', ' service', ' flag', ' src_bytes',\n",
    "       ' dst_bytes', ' land', ' wrong_fragment', ' urgent', ' hot',\n",
    "       ' num_failed_logins', ' logged_in', ' num_compromised', ' root_shell',\n",
    "       ' su_attempted', ' num_root', ' num_file_creations', ' num_shells',\n",
    "       ' num_access_files', ' num_outbound_cmds', ' is_host_login',\n",
    "       ' is_guest_login', ' count', ' srv_count', ' serror_rate',\n",
    "       ' srv_error_rate', ' rerror_rate', ' srv_rerror_rate', ' same_srv_rate',\n",
    "       ' diff_srv_rate', ' srv_diff_host_rate', ' dst_host_count',\n",
    "       ' dst_host_srv_count', ' dst_host_same_srv_rate',\n",
    "       ' dst_host_diff_srv_rate', ' dst_host_same_src_port_rate',\n",
    "       ' dst_host_srv_diff_host_rate', ' dst_host_serror_rate',\n",
    "       ' dst_host_srv_serror_rate', ' dst_host_rerror_rate',\n",
    "       ' dst_host_srv_rerror_rate', 'attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f35cf10-d2a3-45bf-b7c8-bb13f76eb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are extra spaces in column names of each dataset. therefore we will remove them\n",
    "for df in dataframes:\n",
    "    df.columns  = df.columns.str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6536027-acb1-4180-a9fd-2fb0b6fbe7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e449ae3-c0e0-42c9-8f36-e63042036415",
   "metadata": {},
   "source": [
    "# Resampling Data\n",
    "1. For Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69ef716b-25ce-4f43-8a11-7841370f164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a58eeae9-4ff7-4960-93ff-eb52968e01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_normal = combined_df[combined_df['attack'] == 'Normal']\n",
    "df_attack = combined_df[combined_df['attack'] != 'Normal']\n",
    "\n",
    "# Upsample minority class\n",
    "df_attack_upsampled = resample(df_attack,\n",
    "                               replace=True,  # Sample with replacement\n",
    "                               n_samples=len(df_normal),  # Match majority class\n",
    "                               random_state=42)  # For reproducibility\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "balanced_df1 = pd.concat([df_normal, df_attack_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20ca0c-9ce9-457e-bcd0-f9c6a4260632",
   "metadata": {},
   "source": [
    "2. For Multinomial Cassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1adf40b-8dc5-4bb9-beb3-d3c651a69316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the minimum size among the attack types\n",
    "min_size = combined_df['attack'].value_counts().min()\n",
    "\n",
    "# Resample each class to the minimum size\n",
    "balanced_dfs = []\n",
    "for label in combined_df['attack'].unique():\n",
    "    df = combined_df[combined_df['attack'] == label]\n",
    "    df_resampled = resample(df,\n",
    "                            replace=True,  # Sample with replacement\n",
    "                            n_samples=min_size,  # Match minimum size\n",
    "                            random_state=42)  # For reproducibility\n",
    "    balanced_dfs.append(df_resampled)\n",
    "\n",
    "# Combine all resampled dataframes\n",
    "balanced_df2 = pd.concat(balanced_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346571b-05f2-4b37-aac3-fd0464daaa59",
   "metadata": {},
   "source": [
    "# Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287d3e4-732f-4e7c-bb7d-0124ed7921dd",
   "metadata": {},
   "source": [
    "# 1. Binomial Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a5e27d67-81ef-48de-92c5-e98adc92c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal Features: Convert categorical features to numerical values using one-hot encoding\n",
    "\n",
    "balanced_df1 = pd.get_dummies(balanced_df1, columns=['protocol_type', 'service', 'flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01c381f9-cdeb-4cab-a625-c8b93794cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial Features: Ensuring binary features are correctly formatted\n",
    "\n",
    "binary_features = ['land', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login', 'is_guest_login']\n",
    "balanced_df1[binary_features] = balanced_df1[binary_features].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97687246-b1a7-4fb0-ae85-3a701f899e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3487b7b2-a417-47a5-a5e8-d6eed40c3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Features\n",
    "\n",
    "numeric_features = [\n",
    "    'duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot',\n",
    "    'num_failed_logins', 'num_compromised', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'count', 'srv_count',\n",
    "    'serror_rate', 'srv_error_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "balanced_df1[numeric_features] = scaler.fit_transform(balanced_df1[numeric_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168307ab-044c-4a22-b8ac-2ced0efc9a99",
   "metadata": {},
   "source": [
    "# 2. Multinomial Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66cdab2f-8036-4d1c-9577-bc40993c0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal Features: Convert categorical features to numerical values using one-hot encoding\n",
    "\n",
    "balanced_df2 = pd.get_dummies(balanced_df2, columns=['protocol_type', 'service', 'flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94b9a558-de8a-494f-a609-df090682e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial Features: Ensuring binary features are correctly formatted\n",
    "\n",
    "binary_features = ['land', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login', 'is_guest_login']\n",
    "balanced_df2[binary_features] = balanced_df2[binary_features].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee9d4e38-0e13-4cd8-bf5d-cc27819e1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Features\n",
    "\n",
    "numeric_features = [\n",
    "    'duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot',\n",
    "    'num_failed_logins', 'num_compromised', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'count', 'srv_count',\n",
    "    'serror_rate', 'srv_error_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "balanced_df2[numeric_features] = scaler.fit_transform(balanced_df2[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b896d3f-9c58-4fef-b169-55f9a0fbae56",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1572b039-9c73-4343-889f-66b211c66539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823fae0-0ab1-49db-b5b8-b7d129337ef8",
   "metadata": {},
   "source": [
    "1. Binomial Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d5f3ff5-0a69-4180-8a78-1b65ffec3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173263      0]\n",
      " [     4 172759]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    173263\n",
      "           1       1.00      1.00      1.00    172763\n",
      "\n",
      "    accuracy                           1.00    346026\n",
      "   macro avg       1.00      1.00      1.00    346026\n",
      "weighted avg       1.00      1.00      1.00    346026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target variable\n",
    "X = balanced_df1.drop(columns=['attack'])\n",
    "y = balanced_df1['attack'].apply(lambda x: 1 if x != 'Normal' else 0)  # Attack vs. Normal\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a574b-437b-43a6-ba35-93dbe4d43a93",
   "metadata": {},
   "source": [
    "2. Multinomial Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc0fb737-805c-4b20-8f26-cf2ce1a6f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cffe3fc8-b20c-482d-85a8-ff4282c74ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 4 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Back       1.00      1.00      1.00         3\n",
      "BufferOverflow       1.00      1.00      1.00         2\n",
      "      FTPWrite       1.00      1.00      1.00         1\n",
      " GuessPassword       1.00      1.00      1.00         4\n",
      "          NMap       1.00      1.00      1.00         2\n",
      "       Neptune       1.00      1.00      1.00         3\n",
      "        Normal       0.75      1.00      0.86         3\n",
      "     PortSweep       1.00      1.00      1.00         2\n",
      "       RootKit       1.00      1.00      1.00         1\n",
      "         Satan       1.00      0.50      0.67         2\n",
      "         Smurf       1.00      1.00      1.00         1\n",
      "\n",
      "      accuracy                           0.96        24\n",
      "     macro avg       0.98      0.95      0.96        24\n",
      "  weighted avg       0.97      0.96      0.95        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode target variable\n",
    "X = balanced_df2.drop(columns=['attack'])\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(balanced_df2['attack'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2128f3d3-8afd-4380-9134-654a17cd3a63",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd99b9-8e8b-427e-bb09-d7ea011beca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
